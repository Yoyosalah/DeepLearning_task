{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THxjKfmyG-St"
      },
      "source": [
        "# ðŸ§  Deep Learning Practical Assignment (Adult Income Dataset)\n",
        "\n",
        "## ðŸ“Œ Dataset\n",
        "We will use the **Adult Income dataset** (also known as the Census Income dataset).  \n",
        "The task is to predict whether a person earns **more than $50K/year** based on demographic and employment attributes.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETxUv-9oGeuT",
        "outputId": "74c2e005-5922-49c8-f86d-896c2130c231"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   age  workclass  fnlwgt     education  education-num      marital-status  \\\n",
            "0   25    Private  226802          11th              7       Never-married   \n",
            "1   38    Private   89814       HS-grad              9  Married-civ-spouse   \n",
            "2   28  Local-gov  336951    Assoc-acdm             12  Married-civ-spouse   \n",
            "3   44    Private  160323  Some-college             10  Married-civ-spouse   \n",
            "4   18        NaN  103497  Some-college             10       Never-married   \n",
            "\n",
            "          occupation relationship   race     sex  capital-gain  capital-loss  \\\n",
            "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
            "1    Farming-fishing      Husband  White    Male             0             0   \n",
            "2    Protective-serv      Husband  White    Male             0             0   \n",
            "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
            "4                NaN    Own-child  White  Female             0             0   \n",
            "\n",
            "   hours-per-week native-country  class  \n",
            "0              40  United-States  <=50K  \n",
            "1              50  United-States  <=50K  \n",
            "2              40  United-States   >50K  \n",
            "3              40  United-States   >50K  \n",
            "4              30  United-States  <=50K  \n",
            "(48842, 15)\n"
          ]
        }
      ],
      "source": [
        "# Option 1: Using OpenML via scikit-learn\n",
        "from sklearn.datasets import fetch_openml\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Load dataset from OpenML\n",
        "adult = fetch_openml(name=\"adult\", version=2, as_frame=True)\n",
        "df = adult.frame\n",
        "\n",
        "print(df.head())\n",
        "print(df.shape)  # (48842, 15)\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=\"class\")\n",
        "y = df[\"class\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqY4sTfrHQF_"
      },
      "source": [
        "## Part 0: Data Preparation\n",
        "1. Load the dataset into a DataFrame.\n",
        "2. Split the data into **training, validation, and test sets**.  \n",
        "   - Suggested: 70% training, 15% validation, 15% test.\n",
        "3. Apply any necessary preprocessing:\n",
        "   - Handle categorical features (encoding).\n",
        "   - Scale numerical features if needed.\n",
        "4. After training your models, always report results on:\n",
        "   - **Training accuracy**\n",
        "   - **Validation accuracy**\n",
        "   - **Test accuracy**\n",
        "5. At the end of the assignment, **compare all methods** across train, validation, and test sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48842 entries, 0 to 48841\n",
            "Data columns (total 15 columns):\n",
            " #   Column          Non-Null Count  Dtype   \n",
            "---  ------          --------------  -----   \n",
            " 0   age             48842 non-null  int64   \n",
            " 1   workclass       46043 non-null  category\n",
            " 2   fnlwgt          48842 non-null  int64   \n",
            " 3   education       48842 non-null  category\n",
            " 4   education-num   48842 non-null  int64   \n",
            " 5   marital-status  48842 non-null  category\n",
            " 6   occupation      46033 non-null  category\n",
            " 7   relationship    48842 non-null  category\n",
            " 8   race            48842 non-null  category\n",
            " 9   sex             48842 non-null  category\n",
            " 10  capital-gain    48842 non-null  int64   \n",
            " 11  capital-loss    48842 non-null  int64   \n",
            " 12  hours-per-week  48842 non-null  int64   \n",
            " 13  native-country  47985 non-null  category\n",
            " 14  class           48842 non-null  category\n",
            "dtypes: category(9), int64(6)\n",
            "memory usage: 2.7 MB\n",
            "None\n",
            "-------------------------\n",
            "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
            "count  48842.000000  4.884200e+04   48842.000000  48842.000000  48842.000000   \n",
            "mean      38.643585  1.896641e+05      10.078089   1079.067626     87.502314   \n",
            "std       13.710510  1.056040e+05       2.570973   7452.019058    403.004552   \n",
            "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
            "25%       28.000000  1.175505e+05       9.000000      0.000000      0.000000   \n",
            "50%       37.000000  1.781445e+05      10.000000      0.000000      0.000000   \n",
            "75%       48.000000  2.376420e+05      12.000000      0.000000      0.000000   \n",
            "max       90.000000  1.490400e+06      16.000000  99999.000000   4356.000000   \n",
            "\n",
            "       hours-per-week  \n",
            "count    48842.000000  \n",
            "mean        40.422382  \n",
            "std         12.391444  \n",
            "min          1.000000  \n",
            "25%         40.000000  \n",
            "50%         40.000000  \n",
            "75%         45.000000  \n",
            "max         99.000000  \n",
            "-------------------------\n",
            "       workclass education      marital-status      occupation relationship  \\\n",
            "count      46043     48842               48842           46033        48842   \n",
            "unique         8        16                   7              14            6   \n",
            "top      Private   HS-grad  Married-civ-spouse  Prof-specialty      Husband   \n",
            "freq       33906     15784               22379            6172        19716   \n",
            "\n",
            "         race    sex native-country  class  \n",
            "count   48842  48842          47985  48842  \n",
            "unique      5      2             41      2  \n",
            "top     White   Male  United-States  <=50K  \n",
            "freq    41762  32650          43832  37155  \n"
          ]
        }
      ],
      "source": [
        "print(df.info())\n",
        "print('-'*25)\n",
        "print(df.describe())\n",
        "print('-'*25)\n",
        "print(df.describe(include='category'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "duplicates:52\n",
            "after_removing_duplicates:0\n"
          ]
        }
      ],
      "source": [
        "print(f\"duplicates:{df.duplicated().sum()}\")\n",
        "df = df.drop_duplicates()\n",
        "print(f\"after_removing_duplicates:{df.duplicated().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "age                  0\n",
            "workclass         2795\n",
            "fnlwgt               0\n",
            "education            0\n",
            "education-num        0\n",
            "marital-status       0\n",
            "occupation        2805\n",
            "relationship         0\n",
            "race                 0\n",
            "sex                  0\n",
            "capital-gain         0\n",
            "capital-loss         0\n",
            "hours-per-week       0\n",
            "native-country     856\n",
            "class                0\n",
            "dtype: int64\n",
            "-------------------------\n",
            "Total Null:6456\n"
          ]
        }
      ],
      "source": [
        "print(df.isna().sum())\n",
        "print(\"-\"*25)\n",
        "print(f\"Total Null:{df.isna().sum().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numerical_data = df.select_dtypes(include=['float64','int64'])\n",
        "for i in numerical_data:\n",
        "    plt.figure(figsize=(13,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    sns.histplot(data=numerical_data,x=i,kde=True)\n",
        "    plt.subplot(1,2,2)\n",
        "    sns.boxplot(data=numerical_data,y=i)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "workclass:\n",
            " ['Private', 'Local-gov', NaN, 'Self-emp-not-inc', 'Federal-gov', 'State-gov', 'Self-emp-inc', 'Without-pay', 'Never-worked']\n",
            "Categories (8, object): ['Federal-gov', 'Local-gov', 'Never-worked', 'Private', 'Self-emp-inc', 'Self-emp-not-inc', 'State-gov', 'Without-pay'], nunique: 8\n",
            "workclass\n",
            "Private             33860\n",
            "Self-emp-not-inc     3861\n",
            "Local-gov            3136\n",
            "State-gov            1981\n",
            "Self-emp-inc         1694\n",
            "Federal-gov          1432\n",
            "Without-pay            21\n",
            "Never-worked           10\n",
            "Name: count, dtype: int64\n",
            "----------------------------------------\n",
            "education:\n",
            " ['11th', 'HS-grad', 'Assoc-acdm', 'Some-college', '10th', ..., 'Assoc-voc', '9th', '12th', '1st-4th', 'Preschool']\n",
            "Length: 16\n",
            "Categories (16, object): ['10th', '11th', '12th', '1st-4th', ..., 'Masters', 'Preschool', 'Prof-school', 'Some-college'], nunique: 16\n",
            "education\n",
            "HS-grad         15770\n",
            "Some-college    10863\n",
            "Bachelors        8013\n",
            "Masters          2656\n",
            "Assoc-voc        2060\n",
            "11th             1812\n",
            "Assoc-acdm       1601\n",
            "10th             1389\n",
            "7th-8th           954\n",
            "Prof-school       834\n",
            "9th               756\n",
            "12th              655\n",
            "Doctorate         594\n",
            "5th-6th           507\n",
            "1st-4th           245\n",
            "Preschool          81\n",
            "Name: count, dtype: int64\n",
            "----------------------------------------\n",
            "marital-status:\n",
            " ['Never-married', 'Married-civ-spouse', 'Widowed', 'Divorced', 'Separated', 'Married-spouse-absent', 'Married-AF-spouse']\n",
            "Categories (7, object): ['Divorced', 'Married-AF-spouse', 'Married-civ-spouse', 'Married-spouse-absent', 'Never-married', 'Separated', 'Widowed'], nunique: 7\n",
            "marital-status\n",
            "Married-civ-spouse       22366\n",
            "Never-married            16082\n",
            "Divorced                  6630\n",
            "Separated                 1530\n",
            "Widowed                   1518\n",
            "Married-spouse-absent      627\n",
            "Married-AF-spouse           37\n",
            "Name: count, dtype: int64\n",
            "----------------------------------------\n",
            "occupation:\n",
            " ['Machine-op-inspct', 'Farming-fishing', 'Protective-serv', NaN, 'Other-service', ..., 'Sales', 'Priv-house-serv', 'Transport-moving', 'Handlers-cleaners', 'Armed-Forces']\n",
            "Length: 15\n",
            "Categories (14, object): ['Adm-clerical', 'Armed-Forces', 'Craft-repair', 'Exec-managerial', ..., 'Protective-serv', 'Sales', 'Tech-support', 'Transport-moving'], nunique: 14\n",
            "occupation\n",
            "Prof-specialty       6165\n",
            "Craft-repair         6102\n",
            "Exec-managerial      6082\n",
            "Adm-clerical         5606\n",
            "Sales                5501\n",
            "Other-service        4919\n",
            "Machine-op-inspct    3017\n",
            "Transport-moving     2355\n",
            "Handlers-cleaners    2071\n",
            "Farming-fishing      1485\n",
            "Tech-support         1445\n",
            "Protective-serv       982\n",
            "Priv-house-serv       240\n",
            "Armed-Forces           15\n",
            "Name: count, dtype: int64\n",
            "----------------------------------------\n",
            "relationship:\n",
            " ['Own-child', 'Husband', 'Not-in-family', 'Unmarried', 'Wife', 'Other-relative']\n",
            "Categories (6, object): ['Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Unmarried', 'Wife'], nunique: 6\n",
            "relationship\n",
            "Husband           19703\n",
            "Not-in-family     12557\n",
            "Own-child          7569\n",
            "Unmarried          5124\n",
            "Wife               2331\n",
            "Other-relative     1506\n",
            "Name: count, dtype: int64\n",
            "----------------------------------------\n",
            "race:\n",
            " ['Black', 'White', 'Asian-Pac-Islander', 'Other', 'Amer-Indian-Eskimo']\n",
            "Categories (5, object): ['Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White'], nunique: 5\n",
            "race\n",
            "White                 41714\n",
            "Black                  4683\n",
            "Asian-Pac-Islander     1517\n",
            "Amer-Indian-Eskimo      470\n",
            "Other                   406\n",
            "Name: count, dtype: int64\n",
            "----------------------------------------\n",
            "sex:\n",
            " ['Male', 'Female']\n",
            "Categories (2, object): ['Female', 'Male'], nunique: 2\n",
            "sex\n",
            "Male      32614\n",
            "Female    16176\n",
            "Name: count, dtype: int64\n",
            "----------------------------------------\n",
            "native-country:\n",
            " ['United-States', NaN, 'Peru', 'Guatemala', 'Mexico', ..., 'Greece', 'Trinadad&Tobago', 'Outlying-US(Guam-USVI-etc)', 'France', 'Holand-Netherlands']\n",
            "Length: 42\n",
            "Categories (41, object): ['Cambodia', 'Canada', 'China', 'Columbia', ..., 'Trinadad&Tobago', 'United-States', 'Vietnam', 'Yugoslavia'], nunique: 41\n",
            "native-country\n",
            "United-States                 43792\n",
            "Mexico                          943\n",
            "Philippines                     294\n",
            "Germany                         206\n",
            "Puerto-Rico                     184\n",
            "Canada                          182\n",
            "El-Salvador                     155\n",
            "India                           151\n",
            "Cuba                            138\n",
            "England                         127\n",
            "China                           122\n",
            "South                           115\n",
            "Jamaica                         106\n",
            "Italy                           105\n",
            "Dominican-Republic              103\n",
            "Japan                            92\n",
            "Poland                           87\n",
            "Guatemala                        86\n",
            "Vietnam                          86\n",
            "Columbia                         85\n",
            "Haiti                            75\n",
            "Portugal                         67\n",
            "Taiwan                           65\n",
            "Iran                             59\n",
            "Greece                           49\n",
            "Nicaragua                        49\n",
            "Peru                             46\n",
            "Ecuador                          45\n",
            "France                           38\n",
            "Ireland                          37\n",
            "Thailand                         30\n",
            "Hong                             30\n",
            "Cambodia                         28\n",
            "Trinadad&Tobago                  27\n",
            "Outlying-US(Guam-USVI-etc)       23\n",
            "Laos                             23\n",
            "Yugoslavia                       23\n",
            "Scotland                         21\n",
            "Honduras                         20\n",
            "Hungary                          19\n",
            "Holand-Netherlands                1\n",
            "Name: count, dtype: int64\n",
            "----------------------------------------\n",
            "class:\n",
            " ['<=50K', '>50K']\n",
            "Categories (2, object): ['<=50K', '>50K'], nunique: 2\n",
            "class\n",
            "<=50K    37109\n",
            ">50K     11681\n",
            "Name: count, dtype: int64\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "categorical_data = df.select_dtypes(include='category')\n",
        "for c in categorical_data.columns:\n",
        "    print(f\"{c}:\\n {categorical_data[c].unique()}, nunique: {categorical_data[c].nunique()}\")\n",
        "    print(categorical_data[c].value_counts())\n",
        "    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for c in categorical_data:\n",
        "    plt.subplot(1,2,1)\n",
        "    sns.countplot(data=categorical_data , y=c)\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    val = categorical_data[c].value_counts()\n",
        "    plt.pie(val.values,labels=val.index,autopct='%1.2f%%')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df.drop(columns=\"class\")\n",
        "y = df[\"class\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        <=50K\n",
              "1        <=50K\n",
              "2         >50K\n",
              "3         >50K\n",
              "4        <=50K\n",
              "         ...  \n",
              "48837    <=50K\n",
              "48838     >50K\n",
              "48839    <=50K\n",
              "48840    <=50K\n",
              "48841     >50K\n",
              "Name: class, Length: 48790, dtype: category\n",
              "Categories (2, object): ['<=50K', '>50K']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "class\n",
            "1    37109\n",
            "0    11681\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "y = y.apply(lambda x: 1 if x == '<=50K' else 0).astype(int)\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = X.drop(columns='native-country')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import RobustScaler,OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical_cols = X.select_dtypes(include='category').columns\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\",drop='first'))\n",
        "])\n",
        "\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    (\"scaler\", RobustScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    (\"categorical\",categorical_transformer,categorical_cols),\n",
        "    (\"numerical\",numerical_transformer,numerical_cols)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3uG3mAu5HTJI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train:(34153, 13),(34153,)\n",
            "val:(7318, 13),(7318,)\n",
            "test:(7319, 13),(7319,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_tmp,y_train,y_tmp = train_test_split(X,y,test_size=0.3,stratify=y,random_state=42)\n",
        "X_val,X_test,y_val,y_test = train_test_split(X_tmp,y_tmp,test_size=0.5,stratify=y_tmp,random_state=42)\n",
        "\n",
        "print(f\"train:{X_train.shape},{y_train.shape}\")\n",
        "print(f\"val:{X_val.shape},{y_val.shape}\")\n",
        "print(f\"test:{X_test.shape},{y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train:(34153, 57),(34153,)\n",
            "val:(7318, 57),(7318,)\n",
            "test:(7319, 57),(7319,)\n"
          ]
        }
      ],
      "source": [
        "X_train = preprocessor.fit_transform(X_train).toarray()\n",
        "X_val = preprocessor.transform(X_val).toarray()\n",
        "X_test = preprocessor.transform(X_test).toarray()\n",
        "\n",
        "print(f\"train:{X_train.shape},{y_train.shape}\")\n",
        "print(f\"val:{X_val.shape},{y_val.shape}\")\n",
        "print(f\"test:{X_test.shape},{y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPpltt4ZG3fN"
      },
      "source": [
        "\n",
        "## Part 1: Optimizers\n",
        "1. Train the same neural network using:\n",
        "   - Stochastic Gradient Descent (SGD)\n",
        "   - SGD with Momentum\n",
        "   - Adam\n",
        "2. Compare the training and validation accuracy for each optimizer.\n",
        "3. Which optimizer converges the fastest? Which gives the best generalization?\n",
        "4. Explain *why* Adam often performs better than plain SGD.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "wnoISz2rHMJ0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "    Dense(10, activation='relu', input_shape=(57,)),\n",
        "    Dense(1,activation='sigmoid')\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Youss\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From c:\\Users\\Youss\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\Youss\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "34153/34153 [==============================] - 77s 2ms/step - loss: 298.2035 - accuracy: 0.8103 - val_loss: 0.3656 - val_accuracy: 0.8102\n",
            "Epoch 2/10\n",
            " 1665/34153 [>.............................] - ETA: 38s - loss: 0.3722 - accuracy: 0.8114"
          ]
        }
      ],
      "source": [
        "model_sgd = create_model()\n",
        "optimizer = SGD(learning_rate=0.01)\n",
        "model_sgd.compile(optimizer=optimizer,loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_sgd = model_sgd.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10,batch_size=1)\n",
        "history_sgd "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Momentum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_momentum = create_model()\n",
        "optimizer = SGD(learning_rate=0.01,momentum=0.9)\n",
        "model_momentum.compile(optimizer=optimizer,loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_momentum = model_momentum.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10,batch_size=1)\n",
        "history_momentum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_adam = create_model()\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model_adam.compile(optimizer=optimizer,loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_adam = model_adam.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10,batch_size=1)\n",
        "history_adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv6ZlRldHC09"
      },
      "source": [
        "## Part 2: Batch Size\n",
        "1. Train the same model with different batch sizes (e.g., 1, 32, 128, 1024).\n",
        "2. Compare:\n",
        "   - Training speed\n",
        "   - Validation accuracy\n",
        "   - Test accuracy\n",
        "   - Generalization ability\n",
        "3. Which batch size leads to the **noisiest gradient updates**?\n",
        "4. Which batch size generalizes better and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "b = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBodrpTrHLMy"
      },
      "outputs": [],
      "source": [
        "model_b1 = create_model()\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model_b1.compile(optimizer=optimizer,loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_b1 = model_b1.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10,batch_size=1)\n",
        "history_b1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "b = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_b2 = create_model()\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model_b2.compile(optimizer=optimizer,loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_b2 = model_b2.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10,batch_size=32)\n",
        "history_b2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "b = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_b3 = create_model()\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model_b3.compile(optimizer=optimizer,loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_b3 = model_b3.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10,batch_size=128)\n",
        "history_b3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "b = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_b4 = create_model()\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model_b4.compile(optimizer=optimizer,loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_b4 = model_b4.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10,batch_size=1024)\n",
        "history_b4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NDO_bUjHDz3"
      },
      "source": [
        "\n",
        "## Part 3: Overfitting and Regularization\n",
        "1. Train a large neural network (many parameters) on the dataset.\n",
        "2. Observe training vs. validation accuracy.  \n",
        "   - Do you see signs of overfitting?\n",
        "3. Apply regularization techniques:\n",
        "   - **L2 regularization**\n",
        "   - **Dropout**\n",
        "4. Compare the validation results before and after regularization.\n",
        "5. Which regularization method was more effective in reducing overfitting? Why?\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d74t2UPVHKdO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_control = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(57,)),\n",
        "    Dense(10, activation='relu'),\n",
        "    Dense(1,activation='sigmoid')\n",
        "])\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model_control.compile(optimizer=optimizer,loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_control = model_control.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10,batch_size=32)\n",
        "history_control"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "L2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_l2 = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(57,),kernel_regularizer=l2(0.01)),\n",
        "    Dense(10, activation='relu',kernel_regularizer=l2(0.01)),\n",
        "    Dense(1,activation='sigmoid')\n",
        "])\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model_l2.compile(optimizer=optimizer,loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_l2 = model_l2.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10,batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dropout = model = Sequential([\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu', input_shape=(57,)),\n",
        "    Dense(10, activation='relu'),\n",
        "    Dense(1,activation='sigmoid')\n",
        "])\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "model_dropout.compile(optimizer=optimizer,loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_dropout = model_dropout.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10,batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0NQsxyYHFpy"
      },
      "source": [
        "## Part 4: Early Stopping\n",
        "1. Train the model for many epochs without early stopping.  \n",
        "   - Plot training, validation, and test curves.\n",
        "2. Train again with **early stopping** (monitor validation loss).\n",
        "3. Compare the number of epochs trained and the final validation/test accuracy.\n",
        "4. Explain how early stopping helps prevent overfitting.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnqrGbCzHI2V"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3,min_delta=0.01, restore_best_weights=True)\n",
        "history_earlystop = model_control.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10,batch_size=32,callbacks=[early_stopping])\n",
        "history_earlystop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix3ePqRnHHSs"
      },
      "source": [
        "## Part 5: Reflection\n",
        "1. Summarize what you learned about:\n",
        "   - The role of optimizers\n",
        "   - The effect of batch size\n",
        "   - Regularization methods\n",
        "   - Early stopping\n",
        "   - Train/validation/test splits\n",
        "2. If you had to train a deep learning model on a new tabular dataset, what choices would you make for:\n",
        "   - Optimizer\n",
        "   - Batch size\n",
        "   - Regularization\n",
        "   - Early stopping\n",
        "   - Data splitting strategy  \n",
        "   and why?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
